# ü§ñ Assistente Inteligente de Tintas Suvinil

> **Desafio Back IA - Loomi | Time Node AI**
> Conselheiro virtual especializado em recomenda√ß√£o de tintas usando IA e busca sem√¢ntica

![Python](https://img.shields.io/badge/Python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-green)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-pgvector-blue)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-orange)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)

## üìã √çndice

- [üéØ Sobre o Projeto](#-sobre-o-projeto)
- [‚ú® Funcionalidades Implementadas](#-funcionalidades-implementadas)
- [üèóÔ∏è Arquitetura](#Ô∏è-arquitetura)
- [üöÄ Como Executar](#-como-executar)
- [üß™ Testando a API](#-testando-a-api)
- [ü§ñ Stack de IA](#-stack-de-ia)
- [üìä Base de Dados](#-base-de-dados)
- [üõ†Ô∏è Ferramentas de IA Utilizadas](#Ô∏è-ferramentas-de-ia-utilizadas)
- [üîç Decis√µes T√©cnicas](#-decis√µes-t√©cnicas)
- [üìà Performance Observada](#-performance-observada)
- [üé® Pr√≥ximos Passos](#-pr√≥ximos-passos)

## üéØ Sobre o Projeto

Este projeto implementa um **Assistente Inteligente** que atua como especialista virtual em tintas Suvinil, desenvolvido como solu√ß√£o para o Desafio Back IA da Loomi. O sistema combina busca sem√¢ntica com IA conversacional para oferecer recomenda√ß√µes personalizadas de tintas.

### Problema Resolvido
- Consulta inteligente de cat√°logo de tintas baseada em linguagem natural
- Recomenda√ß√µes contextualizadas considerando ambiente, superf√≠cie e necessidades
- Interface conversacional que simula atendimento especializado

### Abordagem T√©cnica
- **RAG (Retrieval-Augmented Generation)** para busca sem√¢ntica em base de produtos
- **LLM** para gera√ß√£o de respostas conversacionais no tom Suvinil
- **Sistema h√≠brido** com fallback para garantir sempre uma resposta

## ‚úÖ Funcionalidades Implementadas

### üß† **Sistema de Recomenda√ß√£o com IA**
- ‚úÖ Busca sem√¢ntica usando OpenAI embeddings + pgvector
- ‚úÖ Similarity search com scoring de relev√¢ncia
- ‚úÖ Sistema de fallback para busca tradicional SQL
- ‚úÖ Tratamento robusto de erros e edge cases

### üí¨ **Chat Conversacional**
- ‚úÖ GPT-4o-mini integrado para respostas naturais
- ‚úÖ Prompt engineering espec√≠fico para tom Suvinil
- ‚úÖ Formato estruturado: recomenda√ß√£o + benef√≠cios + pergunta
- ‚úÖ Contexto dos produtos encontrados enviado ao LLM

### üéØ **API Completa**
- ‚úÖ CRUD para tintas e usu√°rios (implementado previamente)
- ‚úÖ Sistema de autentica√ß√£o JWT com RBAC
- ‚úÖ Documenta√ß√£o autom√°tica com Swagger
- ‚úÖ Endpoints espec√≠ficos para chat com IA
- ‚úÖ Health checks e testes de conectividade

## üèóÔ∏è Arquitetura

### Stack Implementado
- **Backend**: Python 3.11 + FastAPI
- **Banco de Dados**: PostgreSQL 16 + extens√£o pgvector
- **IA**: OpenAI GPT-4o-mini + Embeddings API
- **Deploy**: Docker + Docker Compose
- **Autentica√ß√£o**: JWT implementado em rotas existentes

### Fluxo de Processamento Real
```
Usu√°rio ‚Üí FastAPI ‚Üí Chat Router ‚Üí Recomendador Agent
                                       ‚Üì
                   OpenAI Embeddings ‚Üí pgvector Search
                                       ‚Üì
                   Produtos Relevantes ‚Üí GPT-4o-mini ‚Üí Resposta
```

## üöÄ Como Executar

### Pr√©-requisitos
- Docker & Docker Compose
- Chave da OpenAI API

### 1. Clone e configure
```bash
git clone <repo-url>
cd tintas
cp .env.example .env
# Configure OPENAI_API_KEY no .env
```

### 2. Execute
```bash
docker compose up --build
```

### 3. Acesse
- **API**: http://localhost:8000
- **Docs**: http://localhost:8000/docs
- **Chat**: POST `/chat/recomendar`

## üß™ Testando a API

### Endpoints Funcionais

#### Health Checks
```bash
# Servi√ßo b√°sico
curl http://localhost:8000/chat/health

# Conex√£o com banco (confirma 100 tintas)
curl http://localhost:8000/chat/test-db

# Conex√£o OpenAI (testa embeddings)
curl http://localhost:8000/chat/test-embeddings
```

#### Chat Principal
```bash
curl -X POST "http://localhost:8000/chat/recomendar" \
     -H "Content-Type: application/json" \
     -d '{
       "mensagem": "tinta para cozinha resistente a gordura",
       "limite_produtos": 3
     }'
```

### Resposta Real Observada
```json
{
  "resposta": "Para a cozinha, recomendo a **Suvinil Cl√°ssica**.\n√â resistente ao calor e ideal para ambientes internos.\n\n‚Ä¢ Acabamento acetinado que facilita a limpeza\n‚Ä¢ Resistente √† manchas\n‚Ä¢ Secagem r√°pida, ideal para reformas\n\nüí° Voc√™ j√° pensou na cor que gostaria de usar?",
  "produtos_encontrados": [
    {
      "id": "2257b48c-848c-419e-a472-b253f1318cf0",
      "nome": "Suvinil Criativa",
      "cor": "Cinza Urbano",
      "ambiente": "interno", 
      "acabamento": "fosco",
      "linha": "Econ√¥mica",
      "score": 0.626
    }
  ]
}
```

## ü§ñ Stack de IA

### Componentes Reais

#### üîç **RAG Implementado**
- **Embeddings**: OpenAI `text-embedding-3-small` (1536 dimens√µes)
- **Vector Store**: pgvector no PostgreSQL
- **Retrieval**: Busca por similaridade coseno com `<=>` operator
- **Augmentation**: Contexto estruturado enviado ao LLM

#### üß† **LLM Integration**
- **Modelo**: GPT-4o-mini da OpenAI
- **Input**: Prompt do sistema + contexto dos produtos + query do usu√°rio
- **Output**: Resposta conversacional formatada

#### üõ†Ô∏è **Agente Inteligente**
- **Orquestra√ß√£o**: Fun√ß√£o `recomendar_com_explicacao()` 
- **Ferramentas**: Busca sem√¢ntica + busca SQL (fallback)
- **Decis√£o**: Autom√°tica baseada em disponibilidade de embeddings

### Fluxo T√©cnico Real
1. **Input**: Query do usu√°rio via `/chat/recomendar`
2. **Embedding**: Convers√£o para vetor 1536D via OpenAI
3. **Search**: pgvector similarity search com score
4. **Context**: Formata√ß√£o dos produtos para prompt do LLM
5. **LLM**: GPT-4o-mini gera resposta seguindo template Suvinil
6. **Output**: JSON com resposta + produtos + debug info (opcional)

## üìä Base de Dados

### Dados Confirmados
- **Fonte**: CSV `Base_de_Dados_Tintas_Enriquecida.csv`
- **Total**: 100 produtos Suvinil (confirmado via `/chat/test-db`)
- **Embeddings**: Tabela `embeddings_tintas` populada e funcional

### Schema Implementado
```sql
-- Tabela principal (j√° existia)
CREATE TABLE tintas (
    id UUID PRIMARY KEY,
    nome VARCHAR(255),
    cor VARCHAR(255), 
    superficie_indicada VARCHAR(255),
    ambiente ambiente_enum, -- interno/externo
    acabamento acabamento_enum, -- fosco/acetinado/semibrilho/brilho
    features JSONB,
    linha VARCHAR(100),
    descricao TEXT
);

-- Embeddings para busca sem√¢ntica (adicionada)
CREATE TABLE embeddings_tintas (
    tinta_id UUID PRIMARY KEY REFERENCES tintas(id),
    embedding VECTOR(1536),
    conteudo TEXT,
    atualizado_em TIMESTAMP
);
```

## üõ†Ô∏è Ferramentas de IA Utilizadas

### Desenvolvimento Assistido por IA

#### **Claude (Anthropic)** - Principal ‚≠ê
- **Uso**: 90% do desenvolvimento da funcionalidade de IA
- **Aplica√ß√µes**:
  - Arquitetura do sistema RAG
  - Implementa√ß√£o das fun√ß√µes de busca sem√¢ntica
  - Estrutura√ß√£o do agente inteligente
  - Cria√ß√£o do endpoint `/chat/recomendar`
  - Debugging e otimiza√ß√µes

#### **ChatGPT/OpenAI** - Secund√°rio
- **Uso**: 10% - Principalmente para banco de dados e API base
- **Aplica√ß√µes**:
  - Estrutura√ß√£o inicial da API FastAPI
  - Configura√ß√£o do PostgreSQL + pgvector
  - Gera√ß√£o de dados de teste

### Prompts Reais Utilizados

#### **üìã [Documenta√ß√£o Completa de Prompts](https://drive.google.com/drive/folders/1pm7rh2d2Exgv04R2ougGF3SPddV2mwpF?usp=sharing)**

**Prompts dispon√≠veis na documenta√ß√£o:**

1. **Especialista em Tintas Suvinil** - Prompt principal do sistema
   - Fun√ß√£o, p√∫blico-alvo e comportamento do assistente
   - Estilo de linguagem e formato de respostas
   - Exemplos de intera√ß√µes ideais
   - **Uso**: Base para o sistema de prompts do GPT-4o-mini

2. **Desenvolvimento com Claude** - Prompts t√©cnicos
   - Arquitetura do sistema RAG
   - Implementa√ß√£o de busca sem√¢ntica
   - Integra√ß√£o OpenAI + pgvector
   - **Resultado**: Estrutura modular implementada

3. **Itera√ß√µes e Refinamentos** - Processo de desenvolvimento
   - Debugging e otimiza√ß√µes
   - Ajustes de performance
   - Tratamento de edge cases

## üîç Decis√µes T√©cnicas

### Escolhas Arquiteturais Reais

#### **RAG vs. Fine-tuning**
- **Decis√£o**: RAG com embeddings + retrieval
- **Motivo**: Flexibilidade para atualiza√ß√µes da base sem retreinar
- **Implementa√ß√£o**: OpenAI embeddings + pgvector

#### **Agente √önico vs. Multi-Agentes**
- **Decis√£o**: Agente √∫nico com ferramentas m√∫ltiplas
- **Motivo**: Simplicidade de implementa√ß√£o e manuten√ß√£o
- **Resultado**: Uma fun√ß√£o orquestradora com fallbacks

#### **pgvector vs. Vector DBs externos**
- **Decis√£o**: pgvector integrado ao PostgreSQL existente
- **Motivo**: Aproveitamento da infraestrutura existente
- **Benef√≠cio**: Zero configura√ß√£o adicional de servi√ßos

#### **GPT-4o-mini vs. GPT-4**
- **Decis√£o**: GPT-4o-mini para produ√ß√£o
- **Motivo**: Custo-benef√≠cio adequado para o caso de uso
- **Valida√ß√£o**: Qualidade das respostas atendeu expectativas

### Sistema de Fallback Implementado
```python
try:
    # Tentativa 1: Busca sem√¢ntica
    produtos = buscar_produtos_similares(db, consulta, limite)
    resposta = chamar_llm_para_recomendacao(consulta, produtos)
except Exception:
    # Fallback: Busca SQL tradicional
    produtos = busca_sql_like(db, consulta, limite)
    resposta = resposta_estruturada_simples(produtos)
```

## üìà Performance Observada

### M√©tricas Reais (Postman)
- **Response Time Total**: ~2.6s
- **Status Code**: 200 OK (funcionando)
- **Relev√¢ncia**: Score 0.626 para "cozinha" (boa relev√¢ncia)
- **Disponibilidade**: 100% durante testes

### Componentes de Lat√™ncia (estimados)
- Embedding generation: ~300ms
- Vector search: ~100ms  
- LLM generation: ~2000ms
- Processing overhead: ~200ms

### Custos Estimados
- ~$0.0003 por embedding (1 vez por produto)
- ~$0.001 por resposta LLM
- **Total por consulta**: ~$0.001 USD

## üé® Pr√≥ximos Passos

### Funcionalidades N√£o Implementadas

#### **1. Hist√≥rico de Conversa** 
- **Status**: N√£o implementado
- **Complexidade**: M√©dia
- **Benef√≠cio**: Contexto cont√≠nuo em sess√µes

#### **2. Gera√ß√£o Visual (DALL-E)**
- **Status**: N√£o implementado  
- **Complexidade**: Alta
- **Benef√≠cio**: Visualiza√ß√£o de ambientes pintados

#### **3. Sistema Multi-Agentes**
- **Status**: Arquitetura para futuro
- **Complexidade**: Alta
- **Benef√≠cio**: Especializa√ß√£o por dom√≠nio

### Melhorias T√©cnicas Identificadas

#### **Performance**
- [ ] Cache de embeddings frequentes
- [ ] Otimiza√ß√£o de tokens no prompt
- [ ] Paraleliza√ß√£o de embedding + LLM

#### **Robustez**  
- [ ] Testes automatizados (pytest)
- [ ] Logging estruturado das decis√µes
- [ ] M√©tricas de qualidade das respostas

#### **Observabilidade**
- [ ] Rastreamento do racioc√≠nio do agente
- [ ] Dashboard de performance
- [ ] An√°lise de satisfa√ß√£o do usu√°rio

---

## üìß Sobre o Desenvolvimento

**Desafio Back IA - Loomi**
- **Desenvolvedor**: Paulo Amaral
- **Time**: Node AI  
- **Per√≠odo**: Agosto 2025
- **IA Assistente Principal**: Claude (Anthropic)

### Uso Estrat√©gico de IA no Desenvolvimento
Este projeto demonstra uso pr√°tico de IA como ferramenta de desenvolvimento:
- **90% do c√≥digo de IA** desenvolvido com assist√™ncia do Claude
- **Prompts espec√≠ficos** para cada etapa da implementa√ß√£o
- **Itera√ß√£o r√°pida** permitindo foco na arquitetura e l√≥gica de neg√≥cio
- **Qualidade de c√≥digo** mantida atrav√©s de revis√£o e teste manual

---

*"IA conversacional aplicada ao varejo, desenvolvida com IA"* ü§ñ‚ú®